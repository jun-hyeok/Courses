{"cells":[{"cell_type":"markdown","metadata":{"id":"shDhFi-CoEj6","colab_type":"text"},"source":["# Big Data Analysis Team Project\n","___\n","- Course: AAI3031-01\n","\n","- Term: 2020.05.14 ~ 2020.06.10\n","\n","- Author: 박준혁, 김시인, 최재영, 한승희, 고귀환\n","\n","> Dev-environment\n","- Language: R\n","- Editor: RStudio, Jupyter Notebook/Google Colab(IRkernel)\n","\n","> Target data\n","- Search in [The New York Times](https://www.nytimes.com/) articles (2020.01.21 ~ 2020.05.19)\n","- Get article text by webcrawling ([nyt-webcrawler here](https://colab.research.google.com/drive/1QQqx4NNK9p3wFf5NePZOrR6A0Ipcur6_?usp=sharing))"]},{"cell_type":"markdown","metadata":{"id":"QkRweVhwoEj7","colab_type":"text"},"source":["# 0. Settings"]},{"cell_type":"code","metadata":{"id":"VcQ6JzCeoEj7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":602},"outputId":"0dddbe0e-0e48-49cd-ca2d-3f2b6c75c4a1","executionInfo":{"status":"error","timestamp":1591698561516,"user_tz":-540,"elapsed":1892,"user":{"displayName":"성균관대박준혁","photoUrl":"","userId":"02553656487629704289"}}},"source":["## You can uncomment and run single hash-tagged lines\n","## Pseudo code start with UPPERCASE verb\n","## Install R packages to use if not already installed\n","## command: install.packages('packagename')\n","\n","# install.packages('tm') # Install dependencies together\n","## dependency package required for loading 'tm' package: 'NLP'...\n","\n","# install.packages('textstem') # Install dependencies together\n","## dependency packages required for loading 'textstem' package:'sylly' 'koRpus' 'koRpus.lang.en'\n","\n","# install.packages('rJava') \n","## required for loading 'KoNLP' package\n","\n","# install.packages('KoNLP') \n","## IF NOT INSTALLED : trouble shooting here (https://github.com/haven-jeon/KoNLP)\n","\n","# install.packages('memoise')\n","\n","# install.packages('RColorBrewer')\n","\n","# install.packages('wordcloud2')\n","\n","\n","## ATTACH packages\n","library(plyr);library(dplyr);\n","library(NLP);library(tm);\n","library(sylly);library(koRpus);library(koRpus.lang.en);library(textstem);\n","library(rJava);library(KoNLP);\n","library(memoise);\n","library(RColorBrewer);library(wordcloud2);"],"execution_count":1,"outputs":[{"output_type":"stream","text":["\n","Attaching package: ‘dplyr’\n","\n","\n","The following objects are masked from ‘package:plyr’:\n","\n","    arrange, count, desc, failwith, id, mutate, rename, summarise,\n","    summarize\n","\n","\n","The following objects are masked from ‘package:stats’:\n","\n","    filter, lag\n","\n","\n","The following objects are masked from ‘package:base’:\n","\n","    intersect, setdiff, setequal, union\n","\n","\n"],"name":"stderr"},{"output_type":"error","ename":"ERROR","evalue":"ignored","traceback":["Error in library(NLP): there is no package called ‘NLP’\nTraceback:\n","1. library(NLP)"]},{"output_type":"error","ename":"ERROR","evalue":"ignored","traceback":["Error in library(tm): there is no package called ‘tm’\nTraceback:\n","1. library(tm)"]}]},{"cell_type":"markdown","metadata":{"id":"o_poJU2koEj_","colab_type":"text"},"source":["# 1. Creat combined data file for analysis"]},{"cell_type":"markdown","metadata":{"id":"DeS5keuBoEkA","colab_type":"text"},"source":["## (0) load raw data files "]},{"cell_type":"code","metadata":{"scrolled":true,"id":"TZNqTvZdoEkA","colab_type":"code","colab":{}},"source":["## READ csv data files, THEN GET dataframes 'corona', 'covid'\n","corona <- read.csv('articles_search_coronavirus.csv')\n","covid <- read.csv('articles_search_covid-19.csv')\n","\n","## ADD 'condition' values of each dataframe\n","corona$condition <- 'corona'\n","covid$condition <- 'covid'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QwrleWtnoEkF","colab_type":"code","colab":{}},"source":["## SHOW data info\n","'corona';str(corona)\n","'covid';str(covid)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qhcWT8WSoEkI","colab_type":"text"},"source":["## (1) join the datasets, 'corona' and 'covid'"]},{"cell_type":"code","metadata":{"id":"GqundZqqoEkJ","colab_type":"code","colab":{}},"source":["## MERGE 'corona', 'covid' dataframes, THEN GET new raw dataframe 'rawdf'\n","rawdf <- rbind(corona, covid)\n","\n","## COMPUTE N/As in the dataframe\n","colSums(is.na(rawdf)) # if there is no N/A, it is well combined."],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dDJmVnMxoEkL","colab_type":"text"},"source":["## (2) split the 'date' into 'month' and 'day'"]},{"cell_type":"code","metadata":{"id":"H9G1Z5GgoEkM","colab_type":"code","colab":{}},"source":["## GET 'month', 'day' data FROM data 'date'\n","rawdf$month <- rawdf$date %>% substr(5, 6)\n","rawdf$day <- rawdf$date %>% substr(7, 8)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mYFBKYdqoEkO","colab_type":"text"},"source":["## (3) select needed data"]},{"cell_type":"code","metadata":{"id":"cYQzdOMWoEkP","colab_type":"code","colab":{}},"source":["## SELECT data FROM raw dataframe 'rawdf', THEN GET new dataframe 'df'\n","## needed data:  month, day(just in case), title, text, date (just in case)\n","df <- rawdf %>% dplyr::select(month, day, title, text, date)\n","\n","## SET data labels\n","colnames(df) <- c('Month', 'Day', 'Title', 'Text', 'Date')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9k9dXZDfoEkS","colab_type":"text"},"source":["## (4) combine data, 'Title' and 'Text'"]},{"cell_type":"code","metadata":{"id":"-MgDMkCcoEkS","colab_type":"code","colab":{}},"source":["## MERGE 'Title', 'Text' data, THEN SET data type AS character, THEN GET data 'Article' \n","df$Article <- paste(df$Title, df$Text) %>% as.character()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N8eLr0XGoEkV","colab_type":"text"},"source":["## (5) save dataset into csv file "]},{"cell_type":"code","metadata":{"id":"LtiBBMuDoEkV","colab_type":"code","colab":{}},"source":["## WRITE the dataframe 'df' AS csv file\n","write.csv(df, 'data.csv', row.names = FALSE)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7AS9bgxVoEkY","colab_type":"text"},"source":["# 2. Preprocess using 'tm', 'textstem' packages"]},{"cell_type":"markdown","metadata":{"id":"7SrU60txoEkY","colab_type":"text"},"source":["## (0) load data file, change data types"]},{"cell_type":"code","metadata":{"id":"41l06F4yoEkZ","colab_type":"code","colab":{}},"source":["## READ csv data files, THEN GET dataframes 'data'\n","data <- read.csv('data.csv')\n","\n","## SET data type of data in dataframe AS character\n","data$Article <- data$Article %>% as.character()\n","data$Title <- data$Title %>% as.character()\n","data$Text <- data$Text %>% as.character()\n","\n","## SET variable of data in dataframe\n","article <- data$Article"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"k6qvX4akoEkb","colab_type":"code","colab":{}},"source":["## SHOW data info and an example of data\n","str(data)\n","data %>% tail(1) %>% t()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i449QaL4oEke","colab_type":"text"},"source":["## (1) make all words lowercase "]},{"cell_type":"code","metadata":{"id":"aBnt-s_GoEkf","colab_type":"code","colab":{}},"source":["## SET uppercase letters to lowercase\n","lower <- sapply(article, tolower, USE.NAMES = FALSE)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"hC4ShjJmoEkh","colab_type":"code","colab":{}},"source":["## SHOW an example before lower vs. after lower \n","cbind(article, lower) %>% head(1) %>% substr(1,1000)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iVyubY95oEkm","colab_type":"text"},"source":["## (2) remove meaningless words in article"]},{"cell_type":"code","metadata":{"id":"YgRfMfntoEkm","colab_type":"code","colab":{}},"source":["## REPLACE punctuations (, -.) and numbers WITH space\n","del_punct <- sapply(lower,\n","                    function(x) as.character(gsub('[[:punct:][:digit:]]', ' ', x)),\n","                    USE.NAMES = FALSE)\n","                \n","## DEFINE mystopwords to be deleted\n","## stopwords() in 'tm' package\n","mystopwords <- c(tm::stopwords('en'), \n","            'will', 'can', 'may', \n","            'also', 'still', 'yet', \n","            'much', 'get', 'say', \n","            'one', 'two', 'go') \n","## can add other stopwords in the 'mystopwords' vector \n","                \n","## DELETE 'mystopwords'\n","## removeWord() in 'tm' package\n","del_stopword <- sapply(del_punct,\n","                       function(x) tm::removeWords(x, mystopwords),\n","                       USE.NAMES = FALSE)\n","                     \n","## DELETE one-letter words (like a, s ...)\n","del_oneletter <- sapply(del_stopword,\n","                        function(x) as.character(gsub('\\\\b[a-z]{1}\\\\b', '', x)),\n","                        USE.NAMES = FALSE)\n","\n","## DELETE 2 or more spaces \n","del_space <- sapply(del_oneletter,\n","                    function(x) as.character(gsub('\\\\s+', ' ', x)),\n","                    USE.NAMES = FALSE)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pXhbBVhioEkp","colab_type":"code","colab":{}},"source":["## COMPUTE the number of characters in each step\n","cbind(lower, del_punct,del_stopword, del_oneletter, del_space) %>% nchar() %>% colSums()\n","\n","## SHOW an example of each step (cumulatively applied)\n","cbind(lower, del_punct,del_stopword, del_oneletter, del_space) %>% head(1) %>% substr(1,700)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zx-_LuBJoEkr","colab_type":"text"},"source":["## (3) lemmatize and change data type"]},{"cell_type":"code","metadata":{"id":"t7ykc-t_oEkr","colab_type":"code","colab":{}},"source":["## LEMMANTIZE articles\n","## lemmatize_strings in 'textstem' package\n","lem <- sapply(del_space,\n","              textstem::lemmatize_strings,\n","              USE.NAMES = FALSE)\n","\n","## SET data AS dataframe\n","words <- lem %>% as.data.frame()\n","\n","## SET data label\n","colnames(words) <- 'Word'\n","\n","## SET data type of data in dataframe AS character\n","words$Word <- words$Word %>% as.character()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"SKryaWVroEkv","colab_type":"code","colab":{}},"source":["## COMPUTE the number of characters in each step\n","cbind(del_space, lem) %>% nchar() %>% colSums()\n","\n","## SHOW an example before lem vs. after lem\n","cbind(del_space, lem) %>% head(1) %>% substr(1,1000)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Zjamd8groEkx","colab_type":"text"},"source":["## (4) append 'words' to dataset (and save 'words' separately if needed)"]},{"cell_type":"code","metadata":{"id":"vnV8saf-oEky","colab_type":"code","colab":{}},"source":["## MERGE 'data', 'words' dataframes, THEN GET new dataframe ''\n","dataset <- cbind(data, words)\n","\n","## WRITE the dataframes AS csv files (you can skip)\n","# write.csv(words, 'words.csv', row.names = FALSE)\n","# write.csv(dataset, 'dataset.csv', row.names = FALSE)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"p6FVa1P8oEk0","colab_type":"text"},"source":["# 3. Get unique wordset by month"]},{"cell_type":"markdown","metadata":{"id":"neuWwJe9oEk0","colab_type":"text"},"source":["## (0) load dataset (can skip)"]},{"cell_type":"code","metadata":{"id":"dojwcB8ToEk0","colab_type":"code","colab":{}},"source":["## READ csv data file, THEN GET same dataframes as above'dataset'\n","# dataset <- read.csv('dataset.csv')\n","\n","## SET data AS character\n","# dataset$Word <- dataset$Word %>% as.character()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ync_OdDFoEk3","colab_type":"text"},"source":["## (1) get unique wordset"]},{"cell_type":"code","metadata":{"id":"y_Ps2cxdoEk3","colab_type":"code","colab":{}},"source":["## ADD a new column to the dataset\n","dataset$unique_words <- NA\n","\n","## FOR each row in rows of dataset\n","## SPLIT 'Word' data according to spaces THEN GET only unique words\n","## ADD the unique words TO dataset\n","## ENDFOR\n","for (i in 1:nrow(dataset)) {\n","  row_words <- dataset$Word[i]\n","  listed_unique_words <- lapply(strsplit(row_words, ' '), unique)\n","  unique_words <- unlist(listed_unique_words) %>% paste(collapse = ' ')\n","  dataset$unique_words[i] <- unique_words\n","}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"d3IKskL4oEk5","colab_type":"code","colab":{}},"source":["## COMPUTE the number of characters to compare Word with unique_words\n","dataset %>% dplyr::select(Word,unique_words) %>% nchar() "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"086ux9RBoEk7","colab_type":"text"},"source":["## (2) combine data by month (Jan ~ May)"]},{"cell_type":"code","metadata":{"id":"CrftWwc9oEk7","colab_type":"code","colab":{}},"source":["## GROUP dataset BY Month\n","## THEN MERGE unique_words\n","## THEN GET dataframe'dataset_monthly'\n","dataset_monthly <- dataset %>% \n","    dplyr::group_by(Month) %>% \n","    dplyr::summarise(wordset = paste(unique_words, collapse = ' '))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"X77xlcgeoEk-","colab_type":"code","colab":{}},"source":["## SHOW dataset info \n","dataset_monthly %>% str()\n","## COMPUTE \n","dataset_monthly$wordset %>% t() %>% nchar() #each month has this amount of words "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3W98Mu1roElA","colab_type":"text"},"source":["## (3) divide data sets by month and save as txt file"]},{"cell_type":"code","metadata":{"id":"-L9w06PHoElA","colab_type":"code","colab":{}},"source":["## WRITE the dataframes AS csv files (you can skip)\n","# write.csv(dataset_monthly, 'monthly_words.csv', row.names = F)\n","## it takes long time since a lot of words are in the dataset\n","\n","## SPLIT the dataset INTO 5 dataframes (Jan~May)\n","## corresponding each row (for easier loading)\n","Jan <- dataset_monthly$wordset[1] \n","Feb <- dataset_monthly$wordset[2] \n","Mar <- dataset_monthly$wordset[3] \n","Apr <- dataset_monthly$wordset[4] \n","May <- dataset_monthly$wordset[5]\n","\n","## WRITE txt files\n","write(Jan, 'Jan.txt')\n","write(Feb, 'Feb.txt')\n","write(Mar, 'Mar.txt')\n","write(Apr, 'Apr.txt')\n","write(May, 'May.txt')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QpDV8beMoElD","colab_type":"text"},"source":["# 4. Analysis"]},{"cell_type":"markdown","metadata":{"id":"omRKEC1ZoElD","colab_type":"text"},"source":["## (0) load dataset (can skip)"]},{"cell_type":"code","metadata":{"id":"bVd4qL9yoElE","colab_type":"code","colab":{}},"source":["## READ txt data file, THEN GET same dataset as above (Jan~May)\n","# Jan <- readLines('Jan.txt')\n","# Feb <- readLines('Feb.txt')\n","# Mar <- readLines('Mar.txt')\n","# Apr <- readLines('Apr.txt')\n","# May <- readLines('May.txt')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Th0IGfaRoElG","colab_type":"text"},"source":["## (1) extract nouns "]},{"cell_type":"code","metadata":{"id":"xuMB2ESzoElH","colab_type":"code","colab":{}},"source":["## EXTRACT noun from datasets (Jan~May), THEN GET (noun1~noun5)\n","noun1 <- sapply(Jan, extractNoun, USE.NAMES = F)\n","noun2 <- sapply(Feb, extractNoun, USE.NAMES = F)\n","noun3 <- sapply(Mar, extractNoun, USE.NAMES = F)\n","noun4 <- sapply(Apr, extractNoun, USE.NAMES = F)\n","noun5 <- sapply(May, extractNoun, USE.NAMES = F)\n","## extractNoun in 'KoNLP' package"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uJMJmdnjoElI","colab_type":"text"},"source":["## (2) remove unnecessary words"]},{"cell_type":"code","metadata":{"id":"hW42usDkoElJ","colab_type":"code","colab":{}},"source":["## FOR noun in (noun1~noun5)\n","## REPLACE unnecessary words in noun WITH N/As\n","## REMOVE N/As in noun\n","## ENDFOR\n","\n","## NO1\n","noun1 <- noun1 %>% gsub('people',NA,.)\n","noun1 <- noun1 %>% gsub('say',NA,.)\n","noun1 <- noun1 %>% gsub('one',NA,.)\n","noun1 <- noun1 %>% gsub('also',NA,.)\n","noun1 <- noun1 %>% gsub('will',NA,.)\n","noun1 <- noun1 %>% gsub('day',NA,.)\n","noun1 <- noun1 %>% gsub('make',NA,.)\n","noun1 <- noun1 %>% gsub('take',NA,.)\n","noun1 <- noun1 %>% gsub('two',NA,.)\n","noun1 <- noun1 %>% gsub('like',NA,.)\n","noun1 <- noun1 %>% gsub('case',NA,.)\n","noun1 <- noun1 %>% gsub('go',NA,.)\n","noun1 <- noun1 %>% gsub('can',NA,.)\n","\n","## NO2\n","noun2 <- noun2 %>% gsub('people',NA,.)\n","noun2 <- noun2 %>% gsub('say',NA,.)\n","noun2 <- noun2 %>% gsub('one',NA,.)\n","noun2 <- noun2 %>% gsub('also',NA,.)\n","noun2 <- noun2 %>% gsub('will',NA,.)\n","noun2 <- noun2 %>% gsub('day',NA,.)\n","noun2 <- noun2 %>% gsub('make',NA,.)\n","noun2 <- noun2 %>% gsub('take',NA,.)\n","noun2 <- noun2 %>% gsub('two',NA,.)\n","noun2 <- noun2 %>% gsub('like',NA,.)\n","noun2 <- noun2 %>% gsub('case',NA,.)\n","noun2 <- noun2 %>% gsub('go',NA,.)\n","noun2 <- noun2 %>% gsub('can',NA,.)\n","\n","## NO3\n","noun3 <- noun3 %>% gsub('people',NA,.)\n","noun3 <- noun3 %>% gsub('say',NA,.)\n","noun3 <- noun3 %>% gsub('one',NA,.)\n","noun3 <- noun3 %>% gsub('also',NA,.)\n","noun3 <- noun3 %>% gsub('will',NA,.)\n","noun3 <- noun3 %>% gsub('day',NA,.)\n","noun3 <- noun3 %>% gsub('make',NA,.)\n","noun3 <- noun3 %>% gsub('take',NA,.)\n","noun3 <- noun3 %>% gsub('two',NA,.)\n","noun3 <- noun3 %>% gsub('like',NA,.)\n","noun3 <- noun3 %>% gsub('case',NA,.)\n","noun3 <- noun3 %>% gsub('go',NA,.)\n","noun3 <- noun3 %>% gsub('can',NA,.)\n","\n","\n","## NO4\n","noun4 <- noun4 %>% gsub('people',NA,.)\n","noun4 <- noun4 %>% gsub('say',NA,.)\n","noun4 <- noun4 %>% gsub('one',NA,.)\n","noun4 <- noun4 %>% gsub('also',NA,.)\n","noun4 <- noun4 %>% gsub('will',NA,.)\n","noun4 <- noun4 %>% gsub('day',NA,.)\n","noun4 <- noun4 %>% gsub('make',NA,.)\n","noun4 <- noun4 %>% gsub('take',NA,.)\n","noun4 <- noun4 %>% gsub('two',NA,.)\n","noun4 <- noun4 %>% gsub('like',NA,.)\n","noun4 <- noun4 %>% gsub('case',NA,.)\n","noun4 <- noun4 %>% gsub('go',NA,.)\n","noun4 <- noun4 %>% gsub('can',NA,.)\n","\n","\n","## NO5\n","noun5 <- noun5 %>% gsub('people',NA,.)\n","noun5 <- noun5 %>% gsub('say',NA,.)\n","noun5 <- noun5 %>% gsub('one',NA,.)\n","noun5 <- noun5 %>% gsub('also',NA,.)\n","noun5 <- noun5 %>% gsub('will',NA,.)\n","noun5 <- noun5 %>% gsub('day',NA,.)\n","noun5 <- noun5 %>% gsub('make',NA,.)\n","noun5 <- noun5 %>% gsub('take',NA,.)\n","noun5 <- noun5 %>% gsub('two',NA,.)\n","noun5 <- noun5 %>% gsub('like',NA,.)\n","noun5 <- noun5 %>% gsub('case',NA,.)\n","noun5 <- noun5 %>% gsub('go',NA,.)\n","noun5 <- noun5 %>% gsub('can',NA,.)\n","\n","noun1 <- na.omit(noun1)\n","noun2 <- na.omit(noun2)\n","noun3 <- na.omit(noun3)\n","noun4 <- na.omit(noun4)\n","noun5 <- na.omit(noun5)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P2U3FHM8oElM","colab_type":"text"},"source":["## (3) count nouns"]},{"cell_type":"code","metadata":{"id":"g6tk-fgToElM","colab_type":"code","colab":{}},"source":["## GET tables to count the nouns\n","count_jan <- table(noun1) %>% sort(decreasing = T)\n","count_feb <- table(noun2) %>% sort(decreasing = T)\n","count_mar <- table(noun3) %>% sort(decreasing = T)\n","count_apr <- table(noun4) %>% sort(decreasing = T)\n","count_may <- table(noun5) %>% sort(decreasing = T)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kCLKkrl1oElO","colab_type":"code","colab":{}},"source":["## Word count for the entire period, Top 100\n","count_table <- cbind(count_jan, count_feb, count_mar, count_apr, count_may)\n","count_table %>% head()\n","count_all <- rowSums(count_table) %>% as.table()\n","rowSums(count_table) %>% head(100)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wfYO9pY3oElQ","colab_type":"text"},"source":["## (4) wordcloud of each month"]},{"cell_type":"code","metadata":{"scrolled":false,"id":"ZXOAVRmnoElR","colab_type":"code","colab":{}},"source":["## SET variable 'palette' for argument 'colors'\n","## brewer.pal() in 'RColorBrewer' package\n","palette <- brewer.pal(8, 'Set2')\n","\n","## GET monthly wordclouds \n","## wordcloud2() in 'wordcloud2' package\n","\n","## 1(Jan)\n","wordcloud2(data = count_jan, size=0.7, color = palette)\n","\n","## 2(Feb)\n","wordcloud2(data = count_feb, size=0.7, color = palette)\n","\n","## 3(Mar)\n","wordcloud2(data = count_mar, size=0.7, color = palette)\n","\n","## 4(Apr)\n","wordcloud2(data = count_apr, size=0.7, color = palette)\n","\n","## 5(May)\n","wordcloud2(data = count_may, size=0.7, color = palette)\n","\n","## ALL(Jun~May)\n","wordcloud2(data = count_all, size=0.7, color = palette)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fkwpfeywoElT","colab_type":"text"},"source":["## (5) top 20 words in month"]},{"cell_type":"code","metadata":{"scrolled":false,"id":"fDA1oPqpoElU","colab_type":"code","colab":{}},"source":["## GET monthly barplot, top 20 words \n","par(mar=c(4,7,4,4))\n","barplot(count_jan[1:20], col=palette, las=2, log=\"x\", horiz=T, xlab = \"count\", main = \"Top 20 words in January\")\n","barplot(count_feb[1:20], col=palette, las=2, log=\"x\", horiz=T, xlab = \"count\", main = \"Top 20 words in February\")\n","barplot(count_mar[1:20], col=palette, las=2, log=\"x\", horiz=T, xlab = \"count\", main = \"Top 20 words in March\")\n","barplot(count_apr[1:20], col=palette, las=2, log=\"x\", horiz=T, xlab = \"count\", main = \"Top 20 words in April\")\n","barplot(count_may[1:20], col=palette, las=2, log=\"x\", horiz=T, xlab = \"count\", main = \"Top 20 words in May\")\n","barplot(count_all[1:20], col=palette, las=2, log=\"x\", horiz=T, xlab = \"count\", main = \"Top 20 words\")"],"execution_count":0,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"R","language":"R","name":"ir"},"language_info":{"codemirror_mode":"r","file_extension":".r","mimetype":"text/x-r-source","name":"R","pygments_lexer":"r","version":"3.6.3"},"colab":{"name":"Big Data Analysis Team Project.ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":0}